{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81689885-7cf7-41df-b5f1-79144031a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import re\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41750784-1aa8-4084-8dec-29c2546b0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df = pd.read_csv(\"train_dataset.csv\", encoding=\"utf-16le\")\n",
    "validation_df = pd.read_csv(\"validation_dataset.csv\", encoding=\"utf-16le\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34b2350d-1e13-438c-8957-4b746ab8dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom feature extraction functions\n",
    "def contains_malicious_keywords(text):\n",
    "    keywords = ['CreateObject', 'DocumentOpen', 'Shell', 'GetObject', 'Lib', 'AutoOpen', 'Autoclose', 'StartupPath', 'Open', 'Declare', 'SendKey', 'System',\n",
    "                'PowerShell', 'WScript', 'Start-Process', 'DownloadString', 'ActiveXObject', '.bat', '.vbs', '.ps1', '192.168.1.1', 'Run', 'URLDownloadToFile',\n",
    "'WinHttpRequest','DocumentClose']\n",
    "\n",
    "     \n",
    "    return any(keyword.lower() in text.lower() for keyword in keywords)\n",
    "\n",
    "def calculate_entropy(text):\n",
    "    \"\"\"Calculate the entropy of a given string.\"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    probabilities = [float(text.count(c)) / len(text) for c in set(text)]\n",
    "    entropy = - sum(p * math.log2(p) for p in probabilities)\n",
    "    return entropy\n",
    "\n",
    "def regular_expression_xlstart(text):\n",
    "    pattern = r'If ThisWorkbook\\.Path <> Application\\.Path & \"\\\\XLSTART\" Then ThisWorkbook\\.SaveAs Filename:=Application\\.Path & \"\\\\XLSTART\\\\[^\"]+\\.xls\"'\n",
    "    return 1 if re.match(pattern, text) else 0\n",
    "\n",
    "def count_string_operators(code):\n",
    "    \"\"\"Count the occurrences of string operators in the code.\"\"\"\n",
    "    if not code:\n",
    "        return 0\n",
    "# Define the string operators to be counted\n",
    "    string_operators = ['+', '=', '&']\n",
    "\n",
    "    # Count occurrences of each string operator\n",
    "    operator_counts = {operator: code.count(operator) for operator in string_operators}\n",
    "\n",
    "    return operator_counts\n",
    "\n",
    "def average_string_length(code):\n",
    "    \"\"\"Calculate the average length of strings in the code.\"\"\"\n",
    "    if not code:\n",
    "        return 0.0\n",
    "\n",
    "    # Extract strings from the code\n",
    "    strings = [s.strip('\"') for s in code.split('\"') if len(s.strip('\"')) > 0]\n",
    "\n",
    "    # Calculate the average length\n",
    "    average_length = sum(len(s) for s in strings) / len(strings) if len(strings) > 0 else 0.0\n",
    "\n",
    "    return average_length\n",
    "\n",
    "def calculate_alpha_percentage(code):\n",
    "    \"\"\"Calculate the percentage of alphabetic characters in the code.\"\"\"\n",
    "    if not code:\n",
    "        return 0.0\n",
    "\n",
    "  # Count the total number of characters and the number of alphabetic characters\n",
    "    total_chars = len(code)\n",
    "    alpha_chars = sum(c.isalpha() for c in code)\n",
    "\n",
    "    # Calculate the percentage of alphabetic characters\n",
    "    alpha_percentage = (alpha_chars / total_chars) * 100.0\n",
    "\n",
    "    return alpha_percentage\n",
    "\n",
    "def indicate_unusual_appearance(code):\n",
    "    \"\"\"Indicate the level of unusual appearance of strings in obfuscated macros as a numerical score, normalized to be between 1 and 10.\"\"\"\n",
    "    # Use the previously defined functions\n",
    "    operators_count = count_string_operators(code)\n",
    "    avg_str_length = average_string_length(code)\n",
    "    alpha_percentage = calculate_alpha_percentage(code)\n",
    "\n",
    "    # Initialize a score variable\n",
    "    score = 0\n",
    "\n",
    "    # Define maximum contributions for each component\n",
    "    max_operator_score = 3  # Max score contribution from operators\n",
    "    max_length_score = 3    # Max score contribution from string length\n",
    "    max_alpha_score = 3     # Max score contribution from alpha percentage\n",
    "\n",
    "    # Calculate component scores\n",
    "    operator_score = min(max_operator_score, max(0, operators_count['+'] - 10) / 2)  # Assuming 2 '+' beyond 10 gives max score\n",
    "    length_score = min(max_length_score, max(0, avg_str_length - 20) / 10)  # Assuming 10 units beyond 20 gives max score\n",
    "    alpha_score = min(max_alpha_score, max(0, 30 - alpha_percentage) / 10)  # Assuming 10 percentage points below 30 gives max score\n",
    "\n",
    "    # Sum component scores\n",
    "    score = operator_score + length_score + alpha_score\n",
    "\n",
    "    # Normalize score to 1-10 scale\n",
    "    max_possible_score = max_operator_score + max_length_score + max_alpha_score\n",
    "    normalized_score = 1 + (score / max_possible_score) * 9  # Transform score from 0-max to 1-10\n",
    "\n",
    "    return normalized_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f5f6a8e3-ca57-47ff-ba30-139354973f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(df['vba_code'])\n",
    "X_validation_tfidf = vectorizer.transform(validation_df['vba_code'])\n",
    "\n",
    "# Dimensionality reduction with TruncatedSVD\n",
    "n_features = 100\n",
    "svd = TruncatedSVD(n_components=n_features)\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "X_validation_svd = svd.transform(X_validation_tfidf)\n",
    "\n",
    "# Apply custom feature extraction functions\n",
    "df['malicious_keywords'] = df['vba_code'].apply(contains_malicious_keywords)\n",
    "df['entropy'] = df['vba_code'].apply(calculate_entropy)\n",
    "df['regular_expression_xlstart'] = df['vba_code'].apply(regular_expression_xlstart)\n",
    "df['is_unusual'] = df['vba_code'].apply(indicate_unusual_appearance)\n",
    "\n",
    "validation_df['malicious_keywords'] = validation_df['vba_code'].apply(contains_malicious_keywords)\n",
    "validation_df['entropy'] = validation_df['vba_code'].apply(calculate_entropy)\n",
    "validation_df['regular_expression_xlstart'] = validation_df['vba_code'].apply(regular_expression_xlstart)\n",
    "validation_df['is_unusual'] = validation_df['vba_code'].apply(indicate_unusual_appearance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "592e6610-6297-415a-b7ec-9606213418d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine TF-IDF features with custom features\n",
    "X_train_combined = np.concatenate([X_train_svd, df[['malicious_keywords', 'entropy', 'regular_expression_xlstart', 'is_unusual']].values], axis=1)\n",
    "X_validation_combined = np.concatenate([X_validation_svd, validation_df[['malicious_keywords', 'entropy', 'regular_expression_xlstart', 'is_unusual']].values], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2b693c43-2a6e-4755-9e3d-8ad519b51185",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train RandomForestClassifier\n",
    "y_train = df['label']\n",
    "y_validation = validation_df['label']\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=20)\n",
    "rf_classifier.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_classifier.predict(X_validation_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032d05ce-961a-4f65-a8be-d1878d0bc593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "846c81dc-b8f0-4515-bd0d-046c0800464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.993978737416502\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         mal       1.00      0.99      0.99      5320\n",
      "       white       0.99      1.00      0.99      5309\n",
      "\n",
      "    accuracy                           0.99     10629\n",
      "   macro avg       0.99      0.99      0.99     10629\n",
      "weighted avg       0.99      0.99      0.99     10629\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5263   57]\n",
      " [   7 5302]]\n",
      "False Positive: 57\n",
      "False Negative: 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_validation, y_pred)\n",
    "classification_report_result = classification_report(y_validation, y_pred)\n",
    "confusion = confusion_matrix(y_validation, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_report_result)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "false_positive = confusion[0, 1]\n",
    "false_negative = confusion[1, 0]\n",
    "\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4d72d32c-749c-4411-92d6-8e47f06ae210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5286   34]\n",
      " [  19 5290]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Use the trained model to predict probabilities on the validation set\n",
    "y_prob = rf_classifier.predict_proba(X_validation_combined)\n",
    "\n",
    "# Define a threshold (between 0 and 1) to classify samples as positive or negative\n",
    "threshold = 0.65  # Example threshold, you can adjust this value\n",
    "\n",
    "# Apply the threshold to classify samples\n",
    "y_pred_threshold = (y_prob[:, 1] > threshold).astype(int)  # Assuming positive class is at index 1\n",
    "\n",
    "y_pred_threshold_label = np.where(y_pred_threshold == 1, \"white\", \"mal\")\n",
    " # Evaluate the performance of the model with the adjusted threshold\n",
    "report_threshold = classification_report(y_validation, y_pred_threshold_label)\n",
    "confusion_th = confusion_matrix(y_validation, y_pred_threshold_label)\n",
    " # Print the classification report\n",
    "\n",
    "print(confusion_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0255ac3f-e04d-4d66-95b4-c73a1c3ac7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Assuming rf_classifier is your trained Random Forest classifier\n",
    "\n",
    "# Specify the file path where you want to save the model\n",
    "model_file_path = 'random_forest_model.joblib'\n",
    "\n",
    "# Save the model to the specified file path\n",
    "dump(rf_classifier, model_file_path)\n",
    "\n",
    "print(\"Model saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
