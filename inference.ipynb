{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e821f31-fc4c-497b-8070-53c52e649b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import re\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fe420e8-243d-4fa3-a7fa-8e2b59c833ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom feature extraction functions\n",
    "def contains_malicious_keywords(text):\n",
    "    keywords = ['CreateObject', 'DocumentOpen', 'Shell', 'GetObject', 'Lib', 'AutoOpen', 'Autoclose', 'StartupPath', 'Open', 'Declare', 'SendKey', 'System',\n",
    "                'PowerShell', 'WScript', 'Start-Process', 'DownloadString', 'ActiveXObject', '.bat', '.vbs', '.ps1', '192.168.1.1', 'Run', 'URLDownloadToFile',\n",
    "'WinHttpRequest','DocumentClose']\n",
    "\n",
    "     \n",
    "    return any(keyword.lower() in text.lower() for keyword in keywords)\n",
    "\n",
    "def calculate_entropy(text):\n",
    "    \"\"\"Calculate the entropy of a given string.\"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    probabilities = [float(text.count(c)) / len(text) for c in set(text)]\n",
    "    entropy = - sum(p * math.log2(p) for p in probabilities)\n",
    "    return entropy\n",
    "\n",
    "def regular_expression_xlstart(text):\n",
    "    pattern = r'If ThisWorkbook\\.Path <> Application\\.Path & \"\\\\XLSTART\" Then ThisWorkbook\\.SaveAs Filename:=Application\\.Path & \"\\\\XLSTART\\\\[^\"]+\\.xls\"'\n",
    "    return 1 if re.match(pattern, text) else 0\n",
    "\n",
    "def count_string_operators(code):\n",
    "    \"\"\"Count the occurrences of string operators in the code.\"\"\"\n",
    "    if not code:\n",
    "        return 0\n",
    "# Define the string operators to be counted\n",
    "    string_operators = ['+', '=', '&']\n",
    "\n",
    "    # Count occurrences of each string operator\n",
    "    operator_counts = {operator: code.count(operator) for operator in string_operators}\n",
    "\n",
    "    return operator_counts\n",
    "\n",
    "def average_string_length(code):\n",
    "    \"\"\"Calculate the average length of strings in the code.\"\"\"\n",
    "    if not code:\n",
    "        return 0.0\n",
    "\n",
    "    # Extract strings from the code\n",
    "    strings = [s.strip('\"') for s in code.split('\"') if len(s.strip('\"')) > 0]\n",
    "\n",
    "    # Calculate the average length\n",
    "    average_length = sum(len(s) for s in strings) / len(strings) if len(strings) > 0 else 0.0\n",
    "\n",
    "    return average_length\n",
    "\n",
    "def calculate_alpha_percentage(code):\n",
    "    \"\"\"Calculate the percentage of alphabetic characters in the code.\"\"\"\n",
    "    if not code:\n",
    "        return 0.0\n",
    "\n",
    "  # Count the total number of characters and the number of alphabetic characters\n",
    "    total_chars = len(code)\n",
    "    alpha_chars = sum(c.isalpha() for c in code)\n",
    "\n",
    "    # Calculate the percentage of alphabetic characters\n",
    "    alpha_percentage = (alpha_chars / total_chars) * 100.0\n",
    "\n",
    "    return alpha_percentage\n",
    "\n",
    "def indicate_unusual_appearance(code):\n",
    "    \"\"\"Indicate the level of unusual appearance of strings in obfuscated macros as a numerical score, normalized to be between 1 and 10.\"\"\"\n",
    "    # Use the previously defined functions\n",
    "    operators_count = count_string_operators(code)\n",
    "    avg_str_length = average_string_length(code)\n",
    "    alpha_percentage = calculate_alpha_percentage(code)\n",
    "\n",
    "    # Initialize a score variable\n",
    "    score = 0\n",
    "\n",
    "    # Define maximum contributions for each component\n",
    "    max_operator_score = 3  # Max score contribution from operators\n",
    "    max_length_score = 3    # Max score contribution from string length\n",
    "    max_alpha_score = 3     # Max score contribution from alpha percentage\n",
    "\n",
    "    # Calculate component scores\n",
    "    operator_score = min(max_operator_score, max(0, operators_count['+'] - 10) / 2)  # Assuming 2 '+' beyond 10 gives max score\n",
    "    length_score = min(max_length_score, max(0, avg_str_length - 20) / 10)  # Assuming 10 units beyond 20 gives max score\n",
    "    alpha_score = min(max_alpha_score, max(0, 30 - alpha_percentage) / 10)  # Assuming 10 percentage points below 30 gives max score\n",
    "\n",
    "    # Sum component scores\n",
    "    score = operator_score + length_score + alpha_score\n",
    "\n",
    "    # Normalize score to 1-10 scale\n",
    "    max_possible_score = max_operator_score + max_length_score + max_alpha_score\n",
    "    normalized_score = 1 + (score / max_possible_score) * 9  # Transform score from 0-max to 1-10\n",
    "\n",
    "    return normalized_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdeb38b0-b5cb-49e9-ac97-2b6453ff0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the model, vectorizer, and SVD from disk\n",
    "loaded_model = load('rf_classifier.joblib')\n",
    "vectorizer = load('vectorizer.joblib')\n",
    "svd = load('svd.joblib')\n",
    "\n",
    "# Now, you can use the loaded_model for predictions or further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e89a9e42-3636-4bdd-ab50-70ad6586099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test_dataset_without_labels.csv\", encoding=\"utf-16le\")\n",
    "X_test_tfidf = vectorizer.transform(df_test['vba_code'])\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "\n",
    "# Apply custom feature extraction functions\n",
    "df_test['malicious_keywords'] = df_test['vba_code'].apply(contains_malicious_keywords)\n",
    "df_test['entropy'] = df_test['vba_code'].apply(calculate_entropy)\n",
    "df_test['regular_expression_xlstart'] = df_test['vba_code'].apply(regular_expression_xlstart)\n",
    "df_test['is_unusual'] = df_test['vba_code'].apply(indicate_unusual_appearance)\n",
    "X_test_combined = np.concatenate([X_test_svd, df_test[['malicious_keywords', 'entropy', 'regular_expression_xlstart', 'is_unusual']].values], axis=1)\n",
    "y_test_pred = loaded_model.predict(X_test_combined)\n",
    "\n",
    "# Create a DataFrame to store the predictions\n",
    "predictions_df = pd.DataFrame({'prediction': y_test_pred})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv(\"test_prediction.csv\", index=False, encoding='utf-16-le')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
